{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necesarry Libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Training Data\n",
    "data=pd.read_csv(r'C:\\Users\\gsvas\\Videos\\Captures\\train.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Data to Dataframe and defining X and labels\n",
    "data_ = pd.DataFrame(data)\n",
    "x = data_.drop('target', axis=1)\n",
    "labels = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gsvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\gsvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\gsvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gsvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gsvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing necesarry libraries for NLP preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform Named Entity Recognition\n",
    "def perform_ner_nltk(text_column):\n",
    "    ner_results = []\n",
    "    for text in text_column:\n",
    "        tokens = word_tokenize(text)\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        tree = ne_chunk(pos_tags)\n",
    "        entities = []\n",
    "        for subtree in tree:\n",
    "            if isinstance(subtree, nltk.Tree):\n",
    "                entity = \" \".join([word for word, tag in subtree.leaves()])\n",
    "                label = subtree.label()\n",
    "                entities.append({'text': entity, 'label': label})\n",
    "        ner_results.append(entities)\n",
    "    return ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('deeds', 0.510614541608432), ('forgive', 0.510614541608432), ('allah', 0.44106404207379424), ('reason', 0.3982041761665894), ('earthquake', 0.3541772503550105)]\n"
     ]
    }
   ],
   "source": [
    "text_data = x['text'].fillna('') \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "# \n",
    "row_index = 0  \n",
    "\n",
    "# Get the TF-IDF values for the specified row\n",
    "row_tfidf = tfidf_matrix.getrow(row_index).toarray()\n",
    "\n",
    "# Combine feature names with their corresponding TF-IDF values for the row\n",
    "keywords_for_row = [(feature_names[col], row_tfidf[0, col]) for col in row_tfidf.nonzero()[1]]\n",
    "\n",
    "# Sort the keywords by their TF-IDF values in descending order\n",
    "keywords_for_row.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the keywords for the specified row\n",
    "print(keywords_for_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id      keyword location  \\\n",
      "0         1        deeds      NaN   \n",
      "1         4       forest      NaN   \n",
      "2         5    residents      NaN   \n",
      "3         6       people      NaN   \n",
      "4         7          got      NaN   \n",
      "...     ...          ...      ...   \n",
      "7608  10869          two      NaN   \n",
      "7609  10870  thetawniest      NaN   \n",
      "7610  10871          utc      NaN   \n",
      "7611  10872       police      NaN   \n",
      "7612  10873       latest      NaN   \n",
      "\n",
      "                                                   text  \n",
      "0     Our Deeds are the Reason of this #earthquake M...  \n",
      "1                Forest fire near La Ronge Sask. Canada  \n",
      "2     All residents asked to 'shelter in place' are ...  \n",
      "3     13,000 people receive #wildfires evacuation or...  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...  \n",
      "...                                                 ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...  \n",
      "7611  Police investigating after an e-bike collided ...  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...  \n",
      "\n",
      "[7613 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "for index, row in x.iterrows():\n",
    "    if pd.isnull(row['keyword']):\n",
    "        text = row[\"text\"].lower() if pd.notnull(row[\"text\"]) else \"\"  # Handle NaN values in 'text'\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "        if tokens:\n",
    "            x.at[index, 'keyword'] = tokens[0]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7613 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 238.0+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deeds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>residents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>people</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>got</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>two</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>thetawniest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>latest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword location  \\\n",
       "0         1        deeds      NaN   \n",
       "1         4       forest      NaN   \n",
       "2         5    residents      NaN   \n",
       "3         6       people      NaN   \n",
       "4         7          got      NaN   \n",
       "...     ...          ...      ...   \n",
       "7608  10869          two      NaN   \n",
       "7609  10870  thetawniest      NaN   \n",
       "7610  10871          utc      NaN   \n",
       "7611  10872       police      NaN   \n",
       "7612  10873       latest      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0     Our Deeds are the Reason of this #earthquake M...  \n",
       "1                Forest fire near La Ronge Sask. Canada  \n",
       "2     All residents asked to 'shelter in place' are ...  \n",
       "3     13,000 people receive #wildfires evacuation or...  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...  \n",
       "...                                                 ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...  \n",
       "7611  Police investigating after an e-bike collided ...  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['ner_results_nltk'] = perform_ner_nltk(x['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Function for extracting Location using NLTK and Spacy Libraries \n",
    "def extract_location_entities_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    location_entities = [ent.text for ent in doc.ents if ent.label_ == 'GPE']\n",
    "    return location_entities\n",
    "\n",
    "def extract_location_entities_nltk(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    tree = nltk.ne_chunk(pos_tags)\n",
    "    location_entities = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, nltk.Tree) and subtree.label() == 'GPE':\n",
    "            location_entities.append(\" \".join([word for word, tag in subtree.leaves()]))\n",
    "    return location_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Location Columns using Spacy and NLTK libraries\n",
    "\n",
    "x['location_spacy'] = x['text'].apply(extract_location_entities_spacy)\n",
    "x['location_nltk'] = x['text'].apply(extract_location_entities_nltk)"
x['location'] = x['location_nltk'].apply(lambda loc: loc[0] if isinstance(loc, list) and loc else None)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>ner_results_nltk</th>\n",
       "      <th>location_spacy</th>\n",
       "      <th>location_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deeds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[{'text': 'Reason', 'label': 'ORGANIZATION'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest</td>\n",
       "      <td>Forest</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[{'text': 'Forest', 'label': 'GPE'}, {'text': ...</td>\n",
       "      <td>[Canada]</td>\n",
       "      <td>[Forest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>residents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>people</td>\n",
       "      <td>California</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[{'text': 'California', 'label': 'GPE'}]</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[California]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>got</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>[{'text': 'Ruby', 'label': 'GPE'}]</td>\n",
       "      <td>[Ruby, Alaska]</td>\n",
       "      <td>[Ruby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>two</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>thetawniest</td>\n",
       "      <td>California</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>[{'text': 'California', 'label': 'GPE'}, {'tex...</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[California, Northern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>utc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>[{'text': 'UTC', 'label': 'ORGANIZATION'}, {'t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>police</td>\n",
       "      <td>Little Portugal</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>[{'text': 'Little Portugal', 'label': 'GPE'}]</td>\n",
       "      <td>[Little Portugal]</td>\n",
       "      <td>[Little Portugal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>latest</td>\n",
       "      <td>Northern California Wildfire</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>[{'text': 'Northern California Wildfire', 'lab...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Northern California Wildfire]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword                      location  \\\n",
       "0         1        deeds                           NaN   \n",
       "1         4       forest                        Forest   \n",
       "2         5    residents                           NaN   \n",
       "3         6       people                    California   \n",
       "4         7          got                          Ruby   \n",
       "...     ...          ...                           ...   \n",
       "7608  10869          two                           NaN   \n",
       "7609  10870  thetawniest                    California   \n",
       "7610  10871          utc                           NaN   \n",
       "7611  10872       police               Little Portugal   \n",
       "7612  10873       latest  Northern California Wildfire   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...   \n",
       "1                Forest fire near La Ronge Sask. Canada   \n",
       "2     All residents asked to 'shelter in place' are ...   \n",
       "3     13,000 people receive #wildfires evacuation or...   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...   \n",
       "...                                                 ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "7611  Police investigating after an e-bike collided ...   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "                                       ner_results_nltk     location_spacy  \\\n",
       "0         [{'text': 'Reason', 'label': 'ORGANIZATION'}]                 []   \n",
       "1     [{'text': 'Forest', 'label': 'GPE'}, {'text': ...           [Canada]   \n",
       "2                                                    []                 []   \n",
       "3              [{'text': 'California', 'label': 'GPE'}]       [California]   \n",
       "4                    [{'text': 'Ruby', 'label': 'GPE'}]     [Ruby, Alaska]   \n",
       "...                                                 ...                ...   \n",
       "7608                                                 []                 []   \n",
       "7609  [{'text': 'California', 'label': 'GPE'}, {'tex...       [California]   \n",
       "7610  [{'text': 'UTC', 'label': 'ORGANIZATION'}, {'t...                 []   \n",
       "7611      [{'text': 'Little Portugal', 'label': 'GPE'}]  [Little Portugal]   \n",
       "7612  [{'text': 'Northern California Wildfire', 'lab...                 []   \n",
       "\n",
       "                       location_nltk  \n",
       "0                                 []  \n",
       "1                           [Forest]  \n",
       "2                                 []  \n",
       "3                       [California]  \n",
       "4                             [Ruby]  \n",
       "...                              ...  \n",
       "7608                              []  \n",
       "7609          [California, Northern]  \n",
       "7610                              []  \n",
       "7611               [Little Portugal]  \n",
       "7612  [Northern California Wildfire]  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   int64\n",
      "keyword             object\n",
      "location            object\n",
      "text                object\n",
      "ner_results_nltk    object\n",
      "location_spacy      object\n",
      "location_nltk       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Dummy Variables\n",
    "\n",
    "x_encoded = pd.get_dummies(x, columns=['keyword', 'location','text'])\n",
    "x_numeric=x_encoded.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Pre Trained BERT Tokenizer and Model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "representations = []\n",
    "for text in x['text']:\n",
    "    # Tokenize input text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Forward pass through the model to obtain representations\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    # Access the final layer representations (CLS token) and append to the list\n",
    "    cls_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    representations.append(cls_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.vstack(representations)\n",
    "YY = labels.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Training and Testing Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, YY, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsvas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine Model\n",
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC(kernel='linear')  \n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
      "[LightGBM] [Info] Start training from score -0.279641\n",
      "LightGBM Accuracy: 0.8339\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model \n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',  \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "}\n",
    "num_round = 100\n",
    "lgb_classifier = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "y_pred_lgb = lgb_classifier.predict(X_test, num_iteration=lgb_classifier.best_iteration)\n",
    "y_pred_lgb_binary = (y_pred_lgb >= 0.5).astype(int)\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb_binary)\n",
    "print(f\"LightGBM Accuracy: {accuracy_lgb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
